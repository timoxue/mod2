# -*- coding: utf-8 -*-
import re
import csv
import pdfplumber
from pathlib import Path
from typing import List, Dict
from config import PDF_FILE, CSV_DIR


#PDF_FILE = "åŒ–å­¦è¯å“ä»¿åˆ¶è¯ä¸Šå¸‚è®¸å¯ç”³è¯·æ¨¡å—äºŒè¯å­¦èµ„æ–™æ’°å†™è¦æ±‚ï¼ˆåˆ¶å‰‚ï¼‰ï¼ˆè¯•è¡Œï¼‰.pdf"
OUTPUT_DIR = CSV_DIR

def extract_sections_and_content(pdf_path: str):
    with pdfplumber.open(pdf_path) as pdf:
        pages_text = [(i+1, page.extract_text(x_tolerance=1, y_tolerance=1) or "") for i, page in enumerate(pdf.pages)]
        pages_tables = [(i+1, page.extract_tables()) for i, page in enumerate(pdf.pages)]

    all_lines = []
    for page_num, text in pages_text:
        for line in text.split('\n'):
            line = line.strip()
            if line:
                all_lines.append((page_num, line))

    # ç« èŠ‚ç¼–å·æ­£åˆ™ï¼ˆ3~5çº§ï¼Œå®é™…æœ€é«˜5çº§ï¼‰
    section_id_pattern = r'^2\.3\.P\.\d+(?:\.\d+){0,3}.*'
    sections = []
    i = 0

    while i < len(all_lines):
        page_num, line = all_lines[i]
        if line.startswith("2.3.P.2.1.1"):
            print(line)
        #æ¸…æ™°æ ‡é¢˜ï¼Œå…ˆåˆ¤æ–­ä¸æ˜¯ç›®å½•ï¼Œå†è¿›è¡ŒæŒ‰ç©ºæ ¼åˆ‡åˆ†
        if ".........." in line:
            i += 1
            continue
        section_name = line.split(" ")[0] 
        # è·³è¿‡é¡µçœ‰ï¼ˆå¦‚ "2.3.Påˆ¶å‰‚"ï¼‰
        if re.match(r'^2\.3\.P$', section_name):
            i += 1
            continue

        # åŒ¹é…ç« èŠ‚ç¼–å·ï¼ˆå¦‚ 2.3.P.2.1.1ï¼‰
        if re.match(section_id_pattern, section_name):
            sec_id = section_name
            title = "..."

            # å°è¯•è¯»å–ä¸‹ä¸€è¡Œä½œä¸ºæ ‡é¢˜ï¼ˆéç¼–å·è¡Œï¼‰
            if i + 1 < len(all_lines):
                next_line = all_lines[i+1][1].strip()
                # æ ‡é¢˜ä¸èƒ½æ˜¯å¦ä¸€ä¸ªç« èŠ‚ç¼–å·æˆ–é¡µçœ‰
                if (not re.match(section_id_pattern, next_line) 
                    and not re.match(r'^2\.3\.P$', next_line)
                    and not next_line.isdigit()):  # é¿å…é¡µç 
                    title = next_line
                    i += 2  # è·³è¿‡ç¼–å·+æ ‡é¢˜
                else:
                    i += 1
            else:
                i += 1

            # å»é‡ï¼šä¿ç•™ä¸å« '...' çš„æ ‡é¢˜
            existing = None
            for j, sec in enumerate(sections):
                if sec["id"] == sec_id:
                    existing = j
                    break

            new_sec = {"id": sec_id, "title": title, "start_page": page_num, "focus": "", "tables": []}
            if existing is not None:
                old_sec = sections[existing]
                if "..." in old_sec["title"] and "..." not in title:
                    sections[existing] = new_sec
            else:
                sections.append(new_sec)
        else:
            i += 1

    # ...ï¼ˆåç»­ï¼šæå–å…³æ³¨ç‚¹ã€è¡¨æ ¼ï¼Œå…³è”é¡µç ï¼‰
        elif current and "ã€å…³æ³¨ç‚¹ã€‘" in line:
                # æ”¶é›†å…³æ³¨ç‚¹ï¼ˆç›´åˆ°ä¸‹ä¸€ç« èŠ‚ï¼‰
                idx = all_lines.index((page_num, line))
                focus = ""
                for p, l in all_lines[idx+1:]:
                    if re.match(section_pattern, l) or l.startswith("2.3.P"):
                        break
                    if l and "ã€å…³æ³¨ç‚¹ã€‘" not in l:
                        focus += l + " "
                current["focus"] = re.sub(r'\s+', ' ', focus).strip()

        # å…³è”è¡¨æ ¼ï¼ˆæŒ‰é¡µç åŒºé—´ï¼‰
        for i, sec in enumerate(sections):
            start = sec["start_page"]
            end = sections[i+1]["start_page"] - 1 if i+1 < len(sections) else float('inf')
            tables_in_section = []
            for page_num, tables in pages_tables:
                if start <= page_num <= end:
                    for tbl in tables:
                        if tbl and len(tbl) > 1:
                            tables_in_section.append(tbl)
            sec["tables"] = tables_in_section
    return sections

def generate_csvs(sections: List[Dict], output_dir: str):
    """ç”Ÿæˆ regulations.csv, sections.csv, requirements.csv, checkpoints.csv"""
    Path(output_dir).mkdir(exist_ok=True)

    # 1. regulations.csv
    with open(f"{output_dir}/regulations.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "name", "authority", "publish_date"])
        writer.writeheader()
        writer.writerow({
            "id": "NMPA_MODULE2_2025",
            "name": "åŒ–å­¦è¯å“ä»¿åˆ¶è¯ä¸Šå¸‚è®¸å¯ç”³è¯·æ¨¡å—äºŒè¯å­¦èµ„æ–™æ’°å†™è¦æ±‚ï¼ˆåˆ¶å‰‚ï¼‰ï¼ˆè¯•è¡Œï¼‰",
            "authority": "NMPA",
            "publish_date": "2025-08"
        })

    # 2. sections.csv
    with open(f"{output_dir}/sections.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "regulation_id", "title"])
        writer.writeheader()
        for sec in sections:
            writer.writerow({
                "id": f"SEC_{sec['id'].replace('.', '_')}",
                "regulation_id": "NMPA_MODULE2_2025",
                "title": f"{sec['id']} {sec['title']}"
            })

    # 3. requirements.csv & 4. checkpoints.csv
    requirements = []
    checkpoints = []

    for sec in sections:
        sec_id_clean = sec["id"].replace(".", "_")
        sec_id_neo4j = f"SEC_{sec_id_clean}"
        focus = sec["focus"]
        tables = sec["tables"]

        # === 3.1 è¯­ä¹‰ç±»ï¼šä»ã€å…³æ³¨ç‚¹ã€‘æç‚¼ Requirement ===
        if focus:
            # æç‚¼è¦æ±‚ï¼šå°†â€œå…³æ³¨...â€ â†’ â€œåº”å…³æ³¨...â€ / â€œéœ€è¯„ä¼°...â€
            req_text = focus
            if not req_text.startswith(("åº”", "éœ€", "è¦", "å¿…é¡»", "å»ºè®®")):
                if "å…³æ³¨" in req_text[:10]:
                    req_text = "åº”" + req_text
                else:
                    req_text = "éœ€" + req_text
            req_id = f"REQ_{sec_id_clean}_FOCUS"
            requirements.append({"id": req_id, "section_id": sec_id_neo4j, "text": req_text})

            # å¯¹åº” Checkpoint
            draft = f"æ˜¯å¦{focus.rstrip('ã€‚')}ï¼Ÿ" if not focus.endswith("ï¼Ÿ") else focus
            checkpoints.append({
                "id": f"CHK_{sec_id_clean}_FOCUS",
                "requirement_id": req_id,
                "text": draft,
                "ctd_location": sec["id"],
                "severity": "High"
            })

        # === 3.2 è¡¨æ ¼ç±»ï¼šæ¯ä¸ªè¡¨æ ¼ç‹¬ç«‹ Requirement ===
        for tbl_idx, table in enumerate(tables):
            if len(table) < 2:
                continue
            header = table[0]
            clean_header = [str(h).strip() for h in header if h and str(h).strip()]
            if len(clean_header) < 2:
                continue

            # è¡¨æ ¼ç±» Requirementï¼šæ˜ç¡®è¡¨è¾¾â€œéœ€æä¾›ç»“æ„åŒ–è¡¨æ ¼â€
            req_id_table = f"REQ_{sec_id_clean}_TABLE_{tbl_idx}"
            req_text_table = f"éœ€æä¾›{sec['title']}ç›¸å…³çš„ç»“æ„åŒ–è¡¨æ ¼ï¼ŒåŒ…å«æ˜ç¡®çš„åˆ—å®šä¹‰ã€‚"
            requirements.append({"id": req_id_table, "section_id": sec_id_neo4j, "text": req_text_table})

            # å¯¹åº” Checkpoint
            cols_str = "ã€".join([f"â€˜{col}â€™" for col in clean_header[:5]])
            table_draft = f"æ˜¯å¦æä¾›{sec['title']}ç›¸å…³çš„ç»“æ„åŒ–è¡¨æ ¼ï¼Œä¸”åŒ…å«åˆ—ï¼š{cols_str}ï¼Ÿ"
            checkpoints.append({
                "id": f"CHK_{sec_id_clean}_TABLE_{tbl_idx}",
                "requirement_id": req_id_table,
                "text": table_draft,
                "ctd_location": sec["id"],
                "severity": "Medium"
            })

    # å†™å…¥ requirements.csv
    with open(f"{output_dir}/requirements.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "section_id", "text"])
        writer.writeheader()
        writer.writerows(requirements)

    # å†™å…¥ checkpoints.csv
    with open(f"{output_dir}/checkpoints.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "requirement_id", "text", "ctd_location", "severity"])
        writer.writeheader()
        writer.writerows(checkpoints)

    print(f"âœ… å·²ç”Ÿæˆ 4 ä¸ª CSV æ–‡ä»¶ï¼Œä¿å­˜è‡³: {output_dir}/")
    print(f"   - regulations.csv: 1 æ¡")
    print(f"   - sections.csv: {len(sections)} æ¡")
    print(f"   - requirements.csv: {len(requirements)} æ¡")
    print(f"   - checkpoints.csv: {len(checkpoints)} æ¡")

# ================== ä¸»ç¨‹åº ==================
if __name__ == "__main__":
    if not Path(PDF_FILE).exists():
        raise FileNotFoundError(f"è¯·ç¡®ä¿ PDF æ–‡ä»¶å­˜åœ¨: {PDF_FILE}")

    print("ğŸ” æ­£åœ¨è§£æ PDFï¼Œæå–ç« èŠ‚ã€å…³æ³¨ç‚¹å’Œè¡¨æ ¼...")
    sections = extract_sections_and_content(PDF_FILE)
    generate_csvs(sections, OUTPUT_DIR)