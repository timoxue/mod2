# -*- coding: utf-8 -*-
import re
import csv
import pdfplumber
from pathlib import Path
from typing import List, Dict
from config import PDF_FILE, CSV_DIR


#PDF_FILE = "åŒ–å­¦è¯å“ä»¿åˆ¶è¯ä¸Šå¸‚è®¸å¯ç”³è¯·æ¨¡å—äºŒè¯å­¦èµ„æ–™æ’°å†™è¦æ±‚ï¼ˆåˆ¶å‰‚ï¼‰ï¼ˆè¯•è¡Œï¼‰.pdf"
OUTPUT_DIR = CSV_DIR

def extract_sections_and_content(pdf_path: str):
    """é€šç”¨æå–å™¨ï¼šç« èŠ‚ã€å…³æ³¨ç‚¹ã€è¡¨æ ¼ï¼ˆæŒ‰é¡µç å½’å±ï¼‰"""
    with pdfplumber.open(pdf_path) as pdf:
        pages_text = [(i+1, page.extract_text(x_tolerance=1, y_tolerance=1) or "") for i, page in enumerate(pdf.pages)]
        pages_tables = [(i+1, page.extract_tables()) for i, page in enumerate(pdf.pages)]
        _, text = pages_text[6]
        print(text)
    # è¯†åˆ«ç« èŠ‚ï¼ˆé€šç”¨æ­£åˆ™ï¼‰
    section_pattern = r'^(\d+\.\d+\.P\.\d+(?:\.\d+)*)(?:\s+)(.+).*'

    # åˆå¹¶å…¨æ–‡è¡Œï¼ˆå¸¦é¡µç ï¼‰å¹¶æ‹†åˆ†å‡º4çº§æ ‡é¢˜åŠæ­£æ–‡lines
    all_lines = []
    daopai_lines = []
    chunk = []
    sec_id = "UKN"
    level = 0
    title = 'UKN'
    parent_sid = 'UKN'
    title_list = ''
    idx_line = 0
    sid_map = {}
    title_map = {}
    for page_num, text in pages_text:
        for line in text.split('\n'):
            line = line.strip()
            if line:
                all_lines.append(line)
                match = re.match(section_pattern, line)
                if match and page_num > 2:
                    sec_id = match.group(1).strip()
                    title = match.group(2).strip()
                    level = (len(sec_id)+1) / 2
                    if level == 4:
                        title_list =''
                    title_list = title_list.join( sec_id +';')
            #åŒ…å«page_numçš„åˆ—ä¸ä¿å­˜
            if not line.isdigit():
                chunk.append((title_list, line))


    sections = []
    sec_relations = []
    current = None

    for page_num, line in all_lines:
        if re.match(r'^\d+\.\d+\.P$', line):  # è·³è¿‡ "2.3.P"
            continue
        match = re.match(section_pattern, line)
        # if line.startswith("2.3.P.2.1.1"):
        #     print(line)
        if match:
            sec_id = match.group(1).strip()
            title = match.group(2).strip()
            current = {"id": sec_id, "title": title, "start_page": page_num, "focus": "", "tables": []}
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒ id çš„ç« èŠ‚
            existing = None
            for i, sec in enumerate(sections):
                if sec["id"] == current["id"]:
                    existing = i
                    break

            if existing is not None:
                # å·²å­˜åœ¨ç›¸åŒ id çš„ç« èŠ‚
                existing_sec = sections[existing]
                # åˆ¤æ–­å“ªæ¡æ ‡é¢˜æ›´å®Œæ•´ï¼ˆä¸å« '....'ï¼‰
                if "...." in existing_sec["title"] and "...." not in current["title"]:
                    # æ—§æ ‡é¢˜å« '....'ï¼Œæ–°æ ‡é¢˜å®Œæ•´ â†’ æ›¿æ¢
                    sections[existing] = current
                    current = None
                elif "...." in current["title"] and "...." not in existing_sec["title"]:
                    # æ–°æ ‡é¢˜å« '....'ï¼Œæ—§æ ‡é¢˜å®Œæ•´ â†’ ä¸¢å¼ƒæ–°è®°å½•ï¼Œä¸åš append
                    current = None
                else:
                    # ä¸¤è€…éƒ½å«æˆ–éƒ½ä¸å« '....'ï¼Œä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆæˆ–å¯åˆå¹¶ï¼Œæ­¤å¤„ä¿ç•™åŸé€»è¾‘ï¼‰
                    current = None

            # åªæœ‰ current æœ‰æ•ˆæ—¶æ‰ append
            if current is not None:
                sections.append(current)
        elif current and "ã€å…³æ³¨ç‚¹ã€‘" in line:
            # æ”¶é›†å…³æ³¨ç‚¹ï¼ˆç›´åˆ°ä¸‹ä¸€ç« èŠ‚ï¼‰
            idx = all_lines.index((page_num, line))
            focus = ""
            for p, l in all_lines[idx+1:]:
                if re.match(section_pattern, l) or l.startswith("2.3.P"):
                    break
                if l and "ã€å…³æ³¨ç‚¹ã€‘" not in l:
                    focus += l + " "
            current["focus"] = re.sub(r'\s+', ' ', focus).strip()

    # å…³è”è¡¨æ ¼ï¼ˆæŒ‰é¡µç åŒºé—´ï¼‰
    for i, sec in enumerate(sections):
        start = sec["start_page"]
        end = sections[i+1]["start_page"] - 1 if i+1 < len(sections) else float('inf')
        tables_in_section = []
        for page_num, tables in pages_tables:
            if start <= page_num <= end:
                for tbl in tables:
                    if tbl and len(tbl) > 1:
                        tables_in_section.append(tbl)
        sec["tables"] = tables_in_section

    return sections




def generate_csvs(sections: List[Dict], output_dir: str):
    """ç”Ÿæˆ regulations.csv, sections.csv, requirements.csv, checkpoints.csv"""
    Path(output_dir).mkdir(exist_ok=True)

    # 1. regulations.csv
    with open(f"{output_dir}/regulations.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "name", "authority", "publish_date"])
        writer.writeheader()
        writer.writerow({
            "id": "NMPA_MODULE2_2025",
            "name": "åŒ–å­¦è¯å“ä»¿åˆ¶è¯ä¸Šå¸‚è®¸å¯ç”³è¯·æ¨¡å—äºŒè¯å­¦èµ„æ–™æ’°å†™è¦æ±‚ï¼ˆåˆ¶å‰‚ï¼‰ï¼ˆè¯•è¡Œï¼‰",
            "authority": "NMPA",
            "publish_date": "2025-08"
        })

    # 2. sections.csv
    with open(f"{output_dir}/sections.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "regulation_id", "title"])
        writer.writeheader()
        for sec in sections:
            writer.writerow({
                "id": f"SEC_{sec['id'].replace('.', '_')}",
                "regulation_id": "NMPA_MODULE2_2025",
                "title": f"{sec['id']} {sec['title']}"
            })

    # 3. requirements.csv & 4. checkpoints.csv
    requirements = []
    checkpoints = []

    for sec in sections:
        sec_id_clean = sec["id"].replace(".", "_")
        sec_id_neo4j = f"SEC_{sec_id_clean}"
        focus = sec["focus"]
        tables = sec["tables"]

        # === 3.1 è¯­ä¹‰ç±»ï¼šä»ã€å…³æ³¨ç‚¹ã€‘æç‚¼ Requirement ===
        if focus:
            # æç‚¼è¦æ±‚ï¼šå°†â€œå…³æ³¨...â€ â†’ â€œåº”å…³æ³¨...â€ / â€œéœ€è¯„ä¼°...â€
            req_text = focus
            if not req_text.startswith(("åº”", "éœ€", "è¦", "å¿…é¡»", "å»ºè®®")):
                if "å…³æ³¨" in req_text[:10]:
                    req_text = "åº”" + req_text
                else:
                    req_text = "éœ€" + req_text
            req_id = f"REQ_{sec_id_clean}_FOCUS"
            requirements.append({"id": req_id, "section_id": sec_id_neo4j, "text": req_text})

            # å¯¹åº” Checkpoint
            draft = f"æ˜¯å¦{focus.rstrip('ã€‚')}ï¼Ÿ" if not focus.endswith("ï¼Ÿ") else focus
            checkpoints.append({
                "id": f"CHK_{sec_id_clean}_FOCUS",
                "requirement_id": req_id,
                "text": draft,
                "ctd_location": sec["id"],
                "severity": "High"
            })

        # === 3.2 è¡¨æ ¼ç±»ï¼šæ¯ä¸ªè¡¨æ ¼ç‹¬ç«‹ Requirement ===
        for tbl_idx, table in enumerate(tables):
            if len(table) < 2:
                continue
            header = table[0]
            clean_header = [str(h).strip() for h in header if h and str(h).strip()]
            if len(clean_header) < 2:
                continue

            # è¡¨æ ¼ç±» Requirementï¼šæ˜ç¡®è¡¨è¾¾â€œéœ€æä¾›ç»“æ„åŒ–è¡¨æ ¼â€
            req_id_table = f"REQ_{sec_id_clean}_TABLE_{tbl_idx}"
            req_text_table = f"éœ€æä¾›{sec['title']}ç›¸å…³çš„ç»“æ„åŒ–è¡¨æ ¼ï¼ŒåŒ…å«æ˜ç¡®çš„åˆ—å®šä¹‰ã€‚"
            requirements.append({"id": req_id_table, "section_id": sec_id_neo4j, "text": req_text_table})

            # å¯¹åº” Checkpoint
            cols_str = "ã€".join([f"â€˜{col}â€™" for col in clean_header[:5]])
            table_draft = f"æ˜¯å¦æä¾›{sec['title']}ç›¸å…³çš„ç»“æ„åŒ–è¡¨æ ¼ï¼Œä¸”åŒ…å«åˆ—ï¼š{cols_str}ï¼Ÿ"
            checkpoints.append({
                "id": f"CHK_{sec_id_clean}_TABLE_{tbl_idx}",
                "requirement_id": req_id_table,
                "text": table_draft,
                "ctd_location": sec["id"],
                "severity": "Medium"
            })

    # å†™å…¥ requirements.csv
    with open(f"{output_dir}/requirements.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "section_id", "text"])
        writer.writeheader()
        writer.writerows(requirements)

    # å†™å…¥ checkpoints.csv
    with open(f"{output_dir}/checkpoints.csv", "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, ["id", "requirement_id", "text", "ctd_location", "severity"])
        writer.writeheader()
        writer.writerows(checkpoints)

    print(f"âœ… å·²ç”Ÿæˆ 4 ä¸ª CSV æ–‡ä»¶ï¼Œä¿å­˜è‡³: {output_dir}/")
    print(f"   - regulations.csv: 1 æ¡")
    print(f"   - sections.csv: {len(sections)} æ¡")
    print(f"   - requirements.csv: {len(requirements)} æ¡")
    print(f"   - checkpoints.csv: {len(checkpoints)} æ¡")

# ================== ä¸»ç¨‹åº ==================
if __name__ == "__main__":
    if not Path(PDF_FILE).exists():
        raise FileNotFoundError(f"è¯·ç¡®ä¿ PDF æ–‡ä»¶å­˜åœ¨: {PDF_FILE}")

    print("ğŸ” æ­£åœ¨è§£æ PDFï¼Œæå–ç« èŠ‚ã€å…³æ³¨ç‚¹å’Œè¡¨æ ¼...")
    sections = extract_sections_and_content(PDF_FILE)
    generate_csvs(sections, OUTPUT_DIR)